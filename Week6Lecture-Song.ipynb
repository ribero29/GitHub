{
 "metadata": {
  "name": "",
  "signature": "sha256:9457b67b664782b386e36d0fa27e298edb319fb756ec42af1ac807b753119e46"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Predicting Survival on the Titanic using Logistic Regression by Hojun Song\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "My model will use the independent variables sex, age, fare, sibsp, parch, embarked and pclass to predict the dependent variable survived. \n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 6,
     "metadata": {},
     "source": [
      "Also, I substitued the missing value of age to the mean of age."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "%pylab inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#reading the data from the disk into memory\n",
      "df = pd.read_csv(\"train.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Just a reminder, here are all the column names\n",
      "df.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "Index([u'PassengerId', u'Survived', u'Pclass', u'Name', u'Sex', u'Age', u'SibSp', u'Parch', u'Ticket', u'Fare', u'Cabin', u'Embarked'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Fare</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 714.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 446.000000</td>\n",
        "      <td>   0.383838</td>\n",
        "      <td>   2.308642</td>\n",
        "      <td>  29.699118</td>\n",
        "      <td>   0.523008</td>\n",
        "      <td>   0.381594</td>\n",
        "      <td>  32.204208</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td> 257.353842</td>\n",
        "      <td>   0.486592</td>\n",
        "      <td>   0.836071</td>\n",
        "      <td>  14.526497</td>\n",
        "      <td>   1.102743</td>\n",
        "      <td>   0.806057</td>\n",
        "      <td>  49.693429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.420000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td> 223.500000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>  20.125000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   7.910400</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 446.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  28.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  14.454200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 668.500000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  38.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  31.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 891.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  80.000000</td>\n",
        "      <td>   8.000000</td>\n",
        "      <td>   6.000000</td>\n",
        "      <td> 512.329200</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
        "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
        "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
        "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
        "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
        "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
        "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
        "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
        "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
        "\n",
        "            Parch        Fare  \n",
        "count  891.000000  891.000000  \n",
        "mean     0.381594   32.204208  \n",
        "std      0.806057   49.693429  \n",
        "min      0.000000    0.000000  \n",
        "25%      0.000000    7.910400  \n",
        "50%      0.000000   14.454200  \n",
        "75%      0.000000   31.000000  \n",
        "max      6.000000  512.329200  "
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Impute Age with mean\n",
      "avgAge = df.Age.mean()\n",
      "df.Age = df.Age.fillna(value=avgAge)\n",
      "# Confirm the code is correct\n",
      "#df[df.Age.isnull()]\n",
      "df.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Fare</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>count</th>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "      <td> 891.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>mean</th>\n",
        "      <td> 446.000000</td>\n",
        "      <td>   0.383838</td>\n",
        "      <td>   2.308642</td>\n",
        "      <td>  29.699118</td>\n",
        "      <td>   0.523008</td>\n",
        "      <td>   0.381594</td>\n",
        "      <td>  32.204208</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>std</th>\n",
        "      <td> 257.353842</td>\n",
        "      <td>   0.486592</td>\n",
        "      <td>   0.836071</td>\n",
        "      <td>  13.002015</td>\n",
        "      <td>   1.102743</td>\n",
        "      <td>   0.806057</td>\n",
        "      <td>  49.693429</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>min</th>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.420000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25%</th>\n",
        "      <td> 223.500000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   2.000000</td>\n",
        "      <td>  22.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   7.910400</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>50%</th>\n",
        "      <td> 446.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  29.699118</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  14.454200</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>75%</th>\n",
        "      <td> 668.500000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  35.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   0.000000</td>\n",
        "      <td>  31.000000</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>max</th>\n",
        "      <td> 891.000000</td>\n",
        "      <td>   1.000000</td>\n",
        "      <td>   3.000000</td>\n",
        "      <td>  80.000000</td>\n",
        "      <td>   8.000000</td>\n",
        "      <td>   6.000000</td>\n",
        "      <td> 512.329200</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
        "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
        "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
        "std     257.353842    0.486592    0.836071   13.002015    1.102743   \n",
        "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
        "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
        "50%     446.000000    0.000000    3.000000   29.699118    0.000000   \n",
        "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
        "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
        "\n",
        "            Parch        Fare  \n",
        "count  891.000000  891.000000  \n",
        "mean     0.381594   32.204208  \n",
        "std      0.806057   49.693429  \n",
        "min      0.000000    0.000000  \n",
        "25%      0.000000    7.910400  \n",
        "50%      0.000000   14.454200  \n",
        "75%      0.000000   31.000000  \n",
        "max      6.000000  512.329200  "
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = pd.DataFrame()\n",
      "X['survived'] = df['Survived']\n",
      "X['sex'] = df['Sex']\n",
      "X['age'] = df['Age']\n",
      "X['fare'] = df['Fare']\n",
      "X['sibsp'] = df['SibSp']\n",
      "X['parch'] = df['Parch']\n",
      "X['embarked'] = df['Embarked']\n",
      "X['pclass'] = df['Pclass']\n",
      "#X['cabin'] = df['Cabin']    I tried to use cabin, but it seems useless. So I didn't include it."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 153,
       "text": [
        "(891, 8)"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.pclass.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 154,
       "text": [
        "3    491\n",
        "1    216\n",
        "2    184\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.parch.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 155,
       "text": [
        "0    678\n",
        "1    118\n",
        "2     80\n",
        "5      5\n",
        "3      5\n",
        "4      4\n",
        "6      1\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 155
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.embarked.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 156,
       "text": [
        "S    644\n",
        "C    168\n",
        "Q     77\n",
        "dtype: int64"
       ]
      }
     ],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#I'm going to drop missing values.   That's probably NOT the best strategy, but it's usually good to start simple and \n",
      "#build complexity as you go.\n",
      "#X = X.dropna(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 135
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#survived will be my dependent variable, y.   I'll assign it to y and remove it from X\n",
      "y = X['survived']\n",
      "X = X.drop(['survived'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# We need to handle Sex such that it's categorical, for logistic regression.\n",
      "# Currently it's a string\n",
      "#refer back to last week's lecture if you forget why we're doing this\n",
      "\n",
      "#We can use pandas get_dummies to implement one hot encoding.\n",
      "pd.get_dummies(X.sex)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>female</th>\n",
        "      <th>male</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7  </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9  </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>10 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>11 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>12 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>13 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>14 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>15 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>16 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>17 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>18 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>19 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>20 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>21 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>22 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>23 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>24 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>25 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>26 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>27 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>28 </th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>29 </th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>...</th>\n",
        "      <td>...</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>861</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>862</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>863</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>864</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>865</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>866</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>867</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>868</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>869</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>870</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>871</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>872</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>873</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>874</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>875</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>876</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>877</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>878</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>879</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>880</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>881</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>882</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>883</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>884</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>885</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>886</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>887</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>888</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>889</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>890</th>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>891 rows \u00d7 2 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 158,
       "text": [
        "     female  male\n",
        "0         0     1\n",
        "1         1     0\n",
        "2         1     0\n",
        "3         1     0\n",
        "4         0     1\n",
        "5         0     1\n",
        "6         0     1\n",
        "7         0     1\n",
        "8         1     0\n",
        "9         1     0\n",
        "10        1     0\n",
        "11        1     0\n",
        "12        0     1\n",
        "13        0     1\n",
        "14        1     0\n",
        "15        1     0\n",
        "16        0     1\n",
        "17        0     1\n",
        "18        1     0\n",
        "19        1     0\n",
        "20        0     1\n",
        "21        0     1\n",
        "22        1     0\n",
        "23        0     1\n",
        "24        1     0\n",
        "25        1     0\n",
        "26        0     1\n",
        "27        0     1\n",
        "28        1     0\n",
        "29        0     1\n",
        "..      ...   ...\n",
        "861       0     1\n",
        "862       1     0\n",
        "863       1     0\n",
        "864       0     1\n",
        "865       1     0\n",
        "866       1     0\n",
        "867       0     1\n",
        "868       0     1\n",
        "869       0     1\n",
        "870       0     1\n",
        "871       1     0\n",
        "872       0     1\n",
        "873       0     1\n",
        "874       1     0\n",
        "875       1     0\n",
        "876       0     1\n",
        "877       0     1\n",
        "878       0     1\n",
        "879       1     0\n",
        "880       1     0\n",
        "881       0     1\n",
        "882       1     0\n",
        "883       0     1\n",
        "884       0     1\n",
        "885       1     0\n",
        "886       0     1\n",
        "887       1     0\n",
        "888       1     0\n",
        "889       0     1\n",
        "890       0     1\n",
        "\n",
        "[891 rows x 2 columns]"
       ]
      }
     ],
     "prompt_number": 158
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#IMPORTANT! get_dummies returns an indicator variable for each category.\n",
      "#Refering back to my talk on encoding variables, it's important to drop one category\n",
      "#Otherwise you'll have two perfectly colinear variables.   \n",
      "\n",
      "#Here, since I only have two variables it's easy, I'll just take one, and reassign it to sex\n",
      "#so now Sex becomes female = 1, male = 0\n",
      "X['sex'] = pd.get_dummies(X.sex)['female']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.join(pd.get_dummies(df.Pclass, prefix='pclass'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.drop(['pclass_1', 'pclass'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 161
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.join(pd.get_dummies(df.Embarked, prefix='embarked'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = X.drop(['embarked_C', 'embarked'], axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#remember to scale our features, as with linear regression\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "scaler = StandardScaler()\n",
      "X= scaler.fit_transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build test and training sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 165
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Model Creation\n",
      "At this point I have a test and train set defined.  I will use train to train my model and test to see how accurate the model is.\n",
      "\n",
      "There's one problem with that though.   Lets say my model is right 70% of the time.   Is that good?  Maybe?   \n",
      "\n",
      "I'm going to build a simple 'base rate' model to compare my logistic model to, so we can see if our logistic model is useful or not.  \n",
      "\n",
      "Then, I'll build my logistic model.\n",
      "\n",
      "\n",
      "####Base Rate Model\n",
      "For my baserate model, I'm going to predict that everyone dies."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This function looks for females in the test set and returns 1, survived, otherwise it returns 0\n",
      "def base_rate_model(X):\n",
      "    y = np.zeros(X.shape[0])\n",
      "    return y\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#how accurate is my base rate model?\n",
      "y_base_rate = base_rate_model(X_test)\n",
      "from sklearn.metrics import accuracy_score\n",
      "print \"Base rate accuracy is %2.2f\" % accuracy_score(y_test, y_base_rate)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Base rate accuracy is 0.59\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So, our base model is 61% correct, lets see if logistic can beat it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import LogisticRegression\n",
      "model = LogisticRegression(penalty='l2', C=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 187,
       "text": [
        "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, penalty='l2', random_state=None, tol=0.0001)"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Logistic accuracy is %2.2f\" % accuracy_score(y_test,model.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Logistic accuracy is 0.80\n"
       ]
      }
     ],
     "prompt_number": 188
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Model Comparison\n",
      "\n",
      "Our base model wasn't very good, but it looked better than it was because of class imbalance.  There are many more 0s than 1s in our dataset, so if we just guess 0 we can 'cheat.'\n",
      "\n",
      "A better metric for binary classifer comparisons is AUC or area under the curve. \n",
      "\n",
      "Closely related is [precision and recall](http://scikit-learn.org/stable/auto_examples/plot_precision_recall.html).\n",
      "\n",
      "Precision is the fraction of correctly identified examples of a class (ratio of true positives to all positives).\n",
      "\n",
      "Recall is the fraction of observastions classified in that class that was correctly classified.  \n",
      "\n",
      "Think of fishing with a net for tuna.   \n",
      "*  If our net is very precise, and has high recall it will catch any and all tuna and ONLY tuna.\n",
      "*  If our net is very precise, but has low recall then we might catch one tuna, but most will escape.\n",
      "*  If our net is low precision, but has high recall, then we might catch tuna, but also any other fish around\n",
      "*  If our net is low precision, and low recall, then we should probably give up fishing.   \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import classification_report\n",
      "\n",
      "\n",
      "# I addded cross_validation \n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#a_train, a_test, b_train, b_test = train_test_split(\n",
      "#...     a, b, test_size=0.33, random_state=42)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"---Base Model---\"\n",
      "#base rate AUC\n",
      "base_roc_auc = roc_auc_score(y_test, base_rate_model(X_test))\n",
      "print \"Base Rate AUC = %2.2f\" % base_roc_auc\n",
      "print classification_report(y_test,base_rate_model(X_test) )\n",
      "print \"\\n\\n---Logistic Model---\"\n",
      "#logistic AUC\n",
      "logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
      "print \"Logistic AUC = %2.2f\" % logit_roc_auc\n",
      "print classification_report(y_test, model.predict(X_test) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "---Base Model---\n",
        "Base Rate AUC = 0.50\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.59      1.00      0.74       105\n",
        "          1       0.00      0.00      0.00        74\n",
        "\n",
        "avg / total       0.34      0.59      0.43       179\n",
        "\n",
        "\n",
        "\n",
        "---Logistic Model---\n",
        "Logistic AUC = 0.79\n",
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.81      0.86      0.83       105\n",
        "          1       0.78      0.72      0.75        74\n",
        "\n",
        "avg / total       0.80      0.80      0.80       179\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 191
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "0.80, I satisfied with it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.metrics import roc_curve\n",
      "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 193
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot of a ROC curve for a specific class\n",
      "plt.figure()\n",
      "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % logit_roc_auc)\n",
      "plt.plot([0, 1], [0, 1], 'k--')\n",
      "plt.xlim([0.0, 1.0])\n",
      "plt.ylim([0.0, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('Receiver operating characteristic example')\n",
      "plt.legend(loc=\"lower right\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x170d42b0>"
       ]
      }
     ],
     "prompt_number": 194
    }
   ],
   "metadata": {}
  }
 ]
}