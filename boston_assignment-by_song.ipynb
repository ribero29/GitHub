{
 "metadata": {
  "name": "",
  "signature": "sha256:197039bedbd7ebfb1504ee3677fb07ef56894211e03bdb584faed22801bca4ae"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Boston Housing Assignment\n",
      "\n",
      "In this assignment you'll be using linear regression to estimate the cost of house in boston, using a well known dataset.\n",
      "\n",
      "Goals:\n",
      "+  Measure the performance of the model I created using $R^{2}$ and MSE\n",
      "> Learn how to use sklearn.metrics.r2_score and sklearn.metrics.mean_squared_error\n",
      "+  Implement a new model using L2 regularization\n",
      "> Use sklearn.linear_model.Ridge or sklearn.linear_model.Lasso \n",
      "+  Get the best model you can by optimizing the regularization parameter.   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.metrics import r2_score\n",
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_boston():\n",
      "    scaler = StandardScaler()\n",
      "    boston = dStandardScalerasets.load_boston()\n",
      "    X=boston.data\n",
      "    y=boston.target\n",
      "    X = scaler.fit_transform(X)\n",
      "    return train_test_split(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bean = datasets.load_boston()\n",
      "print bean.DESCR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Boston House Prices dataset\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "http://archive.ics.uci.edu/ml/datasets/Housing\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "**References**\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'data': array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
        "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
        "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
        "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          1.78000000e+01,   3.92830000e+02,   4.03000000e+00],\n",
        "       ..., \n",
        "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.96900000e+02,   5.64000000e+00],\n",
        "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
        "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
        "       'TAX', 'PTRATIO', 'B', 'LSTAT'], \n",
        "      dtype='|S7'), 'DESCR': \"Boston House Prices dataset\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\", 'target': array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
        "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
        "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
        "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
        "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
        "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
        "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
        "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
        "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
        "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
        "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
        "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
        "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
        "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
        "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
        "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
        "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
        "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
        "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
        "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
        "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
        "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
        "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
        "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
        "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
        "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
        "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
        "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
        "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
        "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
        "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
        "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
        "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
        "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
        "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
        "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
        "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
        "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
        "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
        "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
        "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
        "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
        "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
        "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
        "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
        "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
        "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
        "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
        "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
        "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
        "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
        "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
        "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
        "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
        "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
        "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
        "        22. ,  11.9])}\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = load_boston()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(379L, 13L)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(127L, 13L)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fitting a Linear Regression\n",
      "\n",
      "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
      "(line 2) by calling .fit(independent variables, dependent variable)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LinearRegression()\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Making a Prediction\n",
      "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
      "\n",
      "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
      "the value our regressor predicts (clf.predict(X_test))\n",
      "\n",
      "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip (y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "[(11.0, 14.501148494733398),\n",
        " (21.899999999999999, 39.087358915432645),\n",
        " (12.699999999999999, 13.027716849385488),\n",
        " (22.199999999999999, 24.257224925172036),\n",
        " (18.800000000000001, 20.116809707901968),\n",
        " (20.100000000000001, 23.830723687318535),\n",
        " (12.300000000000001, 13.704822272047203),\n",
        " (32.0, 34.358175718213104),\n",
        " (23.199999999999999, 25.650897409288554),\n",
        " (24.5, 20.863353609189254),\n",
        " (25.199999999999999, 27.533445354043494),\n",
        " (24.600000000000001, 29.274511793669504),\n",
        " (23.100000000000001, 26.309312608818296),\n",
        " (14.5, 18.141572281166109),\n",
        " (24.300000000000001, 20.421269830300215),\n",
        " (37.899999999999999, 34.098806088582613),\n",
        " (11.5, 14.963986261085125),\n",
        " (23.899999999999999, 24.760478419240847),\n",
        " (31.5, 33.109612211589386),\n",
        " (24.300000000000001, 24.541095237719261),\n",
        " (30.100000000000001, 35.487004452213185),\n",
        " (19.5, 18.516768412001507),\n",
        " (21.100000000000001, 22.364963927726777),\n",
        " (20.899999999999999, 22.216354916368608),\n",
        " (16.699999999999999, 20.484183560096291),\n",
        " (24.399999999999999, 23.629786104789428),\n",
        " (22.800000000000001, 24.489824732551789),\n",
        " (20.399999999999999, 20.113261784008976),\n",
        " (19.899999999999999, 20.217007026142301),\n",
        " (22.0, 27.464815815874857),\n",
        " (13.1, 21.194360809359889),\n",
        " (22.0, 26.486112821756517),\n",
        " (18.5, 19.682595060458006),\n",
        " (30.5, 30.709212858217857),\n",
        " (37.600000000000001, 38.006277171810346),\n",
        " (13.1, 13.498822553844903),\n",
        " (14.199999999999999, 19.039290892175547),\n",
        " (23.899999999999999, 27.306048744731779),\n",
        " (10.5, 13.366795771312601),\n",
        " (21.5, 24.60993135498309),\n",
        " (32.5, 31.148476927560615),\n",
        " (20.300000000000001, 18.864148051051416),\n",
        " (23.699999999999999, 27.785386330854593),\n",
        " (13.0, 18.004577852720047),\n",
        " (21.699999999999999, 24.181583899201424),\n",
        " (18.100000000000001, 17.2611966374993),\n",
        " (21.199999999999999, 22.820630672687351),\n",
        " (23.5, 31.105106231675773),\n",
        " (14.5, 18.241622764544299),\n",
        " (19.899999999999999, 19.713284255889825),\n",
        " (9.5, 13.104054947613328),\n",
        " (42.299999999999997, 37.832293633535471),\n",
        " (20.0, 16.517748639499434),\n",
        " (31.0, 34.84200719144512),\n",
        " (14.0, 13.319862978876058),\n",
        " (12.5, 20.168019964109867),\n",
        " (19.399999999999999, 19.810562355314733),\n",
        " (23.100000000000001, 22.77221713162826),\n",
        " (32.200000000000003, 32.25044335881492),\n",
        " (18.300000000000001, 20.190479422495855),\n",
        " (24.699999999999999, 23.118308340938512),\n",
        " (31.600000000000001, 34.243675915081219),\n",
        " (16.5, 10.887342656534688),\n",
        " (24.199999999999999, 25.105102026757677),\n",
        " (11.699999999999999, 14.459853874902006),\n",
        " (17.5, 18.603219841620454),\n",
        " (21.199999999999999, 23.10488165171963),\n",
        " (23.199999999999999, 27.536819316504637),\n",
        " (28.699999999999999, 30.963022691979624),\n",
        " (19.399999999999999, 17.485301614735718),\n",
        " (16.0, 18.873695218923565),\n",
        " (17.899999999999999, 0.83809130582191571),\n",
        " (17.5, 16.490976577505279),\n",
        " (20.800000000000001, 19.63150857026497),\n",
        " (18.699999999999999, 18.335325320419908),\n",
        " (13.6, 12.421463464337805),\n",
        " (24.100000000000001, 29.80356165891607),\n",
        " (29.0, 31.975171446713592),\n",
        " (17.100000000000001, 19.435548936436739),\n",
        " (25.0, 27.938798836631392),\n",
        " (33.200000000000003, 32.256472529778982),\n",
        " (46.0, 40.666530386272711),\n",
        " (33.399999999999999, 28.978605823712265),\n",
        " (22.399999999999999, 22.538456291909583),\n",
        " (28.399999999999999, 31.414330815489603),\n",
        " (19.199999999999999, 23.724848532562291),\n",
        " (22.600000000000001, 22.644803434868354),\n",
        " (13.9, 13.344561226806842),\n",
        " (11.800000000000001, 13.45859344739466),\n",
        " (13.4, 13.741884970440326),\n",
        " (22.5, 29.678911450317177),\n",
        " (25.100000000000001, 30.358190046396281),\n",
        " (17.699999999999999, 21.324167419308161),\n",
        " (18.300000000000001, 19.318355135050076),\n",
        " (19.5, 20.915332039045527),\n",
        " (22.300000000000001, 27.683080510031111),\n",
        " (12.6, 19.187220390319457),\n",
        " (35.200000000000003, 35.900412250648813),\n",
        " (19.600000000000001, 21.698512890387033),\n",
        " (20.399999999999999, 23.132802268273156),\n",
        " (17.199999999999999, 16.691668797030175),\n",
        " (38.700000000000003, 35.868498035741474),\n",
        " (21.699999999999999, 20.821970550358557),\n",
        " (20.800000000000001, 23.052559560199896),\n",
        " (23.0, 20.236398424812435),\n",
        " (50.0, 40.63952616536902),\n",
        " (22.399999999999999, 23.804861904844067),\n",
        " (18.399999999999999, 19.866503828546719),\n",
        " (50.0, 37.134516396481658),\n",
        " (17.399999999999999, 15.834764768188332),\n",
        " (14.9, 15.576050242825659),\n",
        " (29.100000000000001, 30.770123173666995),\n",
        " (10.199999999999999, 17.327624246898459),\n",
        " (13.800000000000001, 6.2382507848580673),\n",
        " (36.0, 36.962019548145243),\n",
        " (7.2000000000000002, 8.3489481548784745),\n",
        " (19.100000000000001, 17.316821669838738),\n",
        " (14.9, 18.644439181875249),\n",
        " (17.800000000000001, 16.38178443671611),\n",
        " (23.800000000000001, 25.615826942696266),\n",
        " (23.899999999999999, 28.501894930974434),\n",
        " (22.100000000000001, 27.1001639514405),\n",
        " (18.199999999999999, 18.683415924132099),\n",
        " (9.6999999999999993, 10.424042008332004),\n",
        " (23.100000000000001, 24.401347081463928),\n",
        " (23.199999999999999, 18.204502644424856),\n",
        " (36.200000000000003, 27.812675634741183)]"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implement scikit learn's r2 and mse method to measure the performance of my linear regressor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2_score(y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "0.7287326613056313"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_squared_error(y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "17.207009847554136"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implement sklearn.linear_model.Ridge or sklearn.linear_model.Lasso"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Ridge\n",
      "import numpy as np\n",
      "n_samples, n_features = 10, 5\n",
      "np.random.seed(0)\n",
      "y = np.random.randn(n_samples)\n",
      "X = np.random.randn(n_samples, n_features)\n",
      "clf = Ridge(alpha = 1.0)\n",
      "clf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Optimize the regression model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Evaluate the linear regression\n",
      "def compute_cost(X, y, theta):\n",
      "    m = y.size\n",
      "    y_hat = X.dot(theta)\n",
      "    J = (1.0/2*m)* (y_hat - y).T.dot((y_hat - y))  \n",
      "    return J"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gradient_descent(X, y, theta, alpha, num_iters):\n",
      "   \n",
      "    m = y.size\n",
      "    J_history = np.zeros(shape=(num_iters, 1)) # a column vec to hold our previous Js\n",
      " \n",
      "    for i in range(num_iters):\n",
      "        gradient = (1.0/2*m) * (( y - X.dot(theta)).T.dot(X)).T\n",
      "        theta =  theta + (alpha * gradient)\n",
      "        J_history[i, 0] = compute_cost(X, y, theta)\n",
      "    return theta, J_history"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import *\n",
      "def plot_grad_descent(alpha, iterNum):\n",
      "    theta = np.zeros((X.shape[1],1))#reinitialize theta\n",
      "    theta, J_history = gradient_descent(X, y,theta, alpha, iterNum)\n",
      "    plot(J_history)\n",
      "    title(\"alpha = \" +str(alpha)+ \"; iterations = \" +str(iterNum))\n",
      "    show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_grad_descent(01,10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "setting an array element with a sequence.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-30-74b7627a9b87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_grad_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m01\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-25-4627c6fc9183>\u001b[0m in \u001b[0;36mplot_grad_descent\u001b[1;34m(alpha, iterNum)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot_grad_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#reinitialize theta\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"alpha = \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"; iterations = \"\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-24-05aa80fff41e>\u001b[0m in \u001b[0;36mgradient_descent\u001b[1;34m(X, y, theta, alpha, num_iters)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mgradient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtheta\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtheta\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mJ_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJ_history\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}