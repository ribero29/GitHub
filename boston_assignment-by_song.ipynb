{
 "metadata": {
  "name": "",
  "signature": "sha256:3901be89b8e9526d22f06c8c2b2b133d8385ec0f4d18df7152e735a243cb0e33"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Boston Housing Assignment\n",
      "\n",
      "In this assignment you'll be using linear regression to estimate the cost of house in boston, using a well known dataset.\n",
      "\n",
      "Goals:\n",
      "+  Measure the performance of the model I created using $R^{2}$ and MSE\n",
      "> Learn how to use sklearn.metrics.r2_score and sklearn.metrics.mean_squared_error\n",
      "+  Implement a new model using L2 regularization\n",
      "> Use sklearn.linear_model.Ridge or sklearn.linear_model.Lasso \n",
      "+  Get the best model you can by optimizing the regularization parameter.   "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.metrics import r2_score\n",
      "from sklearn.linear_model import LinearRegression"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_boston():\n",
      "    scaler = StandardScaler()\n",
      "    boston = datasets.load_boston()\n",
      "    X=boston.data\n",
      "    y=boston.target\n",
      "    X = scaler.fit_transform(X)\n",
      "    return train_test_split(X,y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.14404357  1.45427351  0.76103773  0.12167502  0.44386323]\n",
        " [ 0.33367433  1.49407907 -0.20515826  0.3130677  -0.85409574]\n",
        " [-2.55298982  0.6536186   0.8644362  -0.74216502  2.26975462]\n",
        " [-1.45436567  0.04575852 -0.18718385  1.53277921  1.46935877]\n",
        " [ 0.15494743  0.37816252 -0.88778575 -1.98079647 -0.34791215]\n",
        " [ 0.15634897  1.23029068  1.20237985 -0.38732682 -0.30230275]\n",
        " [-1.04855297 -1.42001794 -1.70627019  1.9507754  -0.50965218]\n",
        " [-0.4380743  -1.25279536  0.77749036 -1.61389785 -0.21274028]\n",
        " [-0.89546656  0.3869025  -0.51080514 -1.18063218 -0.02818223]\n",
        " [ 0.42833187  0.06651722  0.3024719  -0.63432209 -0.36274117]]\n"
       ]
      }
     ],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 1.76405235  0.40015721  0.97873798  2.2408932   1.86755799 -0.97727788\n",
        "  0.95008842 -0.15135721 -0.10321885  0.4105985 ]\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bean = datasets.load_boston()\n",
      "print bean.DESCR"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Boston House Prices dataset\n",
        "\n",
        "Notes\n",
        "------\n",
        "Data Set Characteristics:  \n",
        "\n",
        "    :Number of Instances: 506 \n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive\n",
        "    \n",
        "    :Median Value (attribute 14) is usually the target\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        - CRIM     per capita crime rate by town\n",
        "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        - INDUS    proportion of non-retail business acres per town\n",
        "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        - NOX      nitric oxides concentration (parts per 10 million)\n",
        "        - RM       average number of rooms per dwelling\n",
        "        - AGE      proportion of owner-occupied units built prior to 1940\n",
        "        - DIS      weighted distances to five Boston employment centres\n",
        "        - RAD      index of accessibility to radial highways\n",
        "        - TAX      full-value property-tax rate per $10,000\n",
        "        - PTRATIO  pupil-teacher ratio by town\n",
        "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        - LSTAT    % lower status of the population\n",
        "        - MEDV     Median value of owner-occupied homes in $1000's\n",
        "\n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of UCI ML housing dataset.\n",
        "http://archive.ics.uci.edu/ml/datasets/Housing\n",
        "\n",
        "\n",
        "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
        "\n",
        "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        "prices and the demand for clean air', J. Environ. Economics & Management,\n",
        "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        "pages 244-261 of the latter.\n",
        "\n",
        "The Boston house-price data has been used in many machine learning papers that address regression\n",
        "problems.   \n",
        "     \n",
        "**References**\n",
        "\n",
        "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
        "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
        "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bean"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'data': array([[  6.32000000e-03,   1.80000000e+01,   2.31000000e+00, ...,\n",
        "          1.53000000e+01,   3.96900000e+02,   4.98000000e+00],\n",
        "       [  2.73100000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          1.78000000e+01,   3.96900000e+02,   9.14000000e+00],\n",
        "       [  2.72900000e-02,   0.00000000e+00,   7.07000000e+00, ...,\n",
        "          1.78000000e+01,   3.92830000e+02,   4.03000000e+00],\n",
        "       ..., \n",
        "       [  6.07600000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.96900000e+02,   5.64000000e+00],\n",
        "       [  1.09590000e-01,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.93450000e+02,   6.48000000e+00],\n",
        "       [  4.74100000e-02,   0.00000000e+00,   1.19300000e+01, ...,\n",
        "          2.10000000e+01,   3.96900000e+02,   7.88000000e+00]]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
        "       'TAX', 'PTRATIO', 'B', 'LSTAT'], \n",
        "      dtype='|S7'), 'DESCR': \"Boston House Prices dataset\\n\\nNotes\\n------\\nData Set Characteristics:  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive\\n    \\n    :Median Value (attribute 14) is usually the target\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttp://archive.ics.uci.edu/ml/datasets/Housing\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n**References**\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\\n\", 'target': array([ 24. ,  21.6,  34.7,  33.4,  36.2,  28.7,  22.9,  27.1,  16.5,\n",
        "        18.9,  15. ,  18.9,  21.7,  20.4,  18.2,  19.9,  23.1,  17.5,\n",
        "        20.2,  18.2,  13.6,  19.6,  15.2,  14.5,  15.6,  13.9,  16.6,\n",
        "        14.8,  18.4,  21. ,  12.7,  14.5,  13.2,  13.1,  13.5,  18.9,\n",
        "        20. ,  21. ,  24.7,  30.8,  34.9,  26.6,  25.3,  24.7,  21.2,\n",
        "        19.3,  20. ,  16.6,  14.4,  19.4,  19.7,  20.5,  25. ,  23.4,\n",
        "        18.9,  35.4,  24.7,  31.6,  23.3,  19.6,  18.7,  16. ,  22.2,\n",
        "        25. ,  33. ,  23.5,  19.4,  22. ,  17.4,  20.9,  24.2,  21.7,\n",
        "        22.8,  23.4,  24.1,  21.4,  20. ,  20.8,  21.2,  20.3,  28. ,\n",
        "        23.9,  24.8,  22.9,  23.9,  26.6,  22.5,  22.2,  23.6,  28.7,\n",
        "        22.6,  22. ,  22.9,  25. ,  20.6,  28.4,  21.4,  38.7,  43.8,\n",
        "        33.2,  27.5,  26.5,  18.6,  19.3,  20.1,  19.5,  19.5,  20.4,\n",
        "        19.8,  19.4,  21.7,  22.8,  18.8,  18.7,  18.5,  18.3,  21.2,\n",
        "        19.2,  20.4,  19.3,  22. ,  20.3,  20.5,  17.3,  18.8,  21.4,\n",
        "        15.7,  16.2,  18. ,  14.3,  19.2,  19.6,  23. ,  18.4,  15.6,\n",
        "        18.1,  17.4,  17.1,  13.3,  17.8,  14. ,  14.4,  13.4,  15.6,\n",
        "        11.8,  13.8,  15.6,  14.6,  17.8,  15.4,  21.5,  19.6,  15.3,\n",
        "        19.4,  17. ,  15.6,  13.1,  41.3,  24.3,  23.3,  27. ,  50. ,\n",
        "        50. ,  50. ,  22.7,  25. ,  50. ,  23.8,  23.8,  22.3,  17.4,\n",
        "        19.1,  23.1,  23.6,  22.6,  29.4,  23.2,  24.6,  29.9,  37.2,\n",
        "        39.8,  36.2,  37.9,  32.5,  26.4,  29.6,  50. ,  32. ,  29.8,\n",
        "        34.9,  37. ,  30.5,  36.4,  31.1,  29.1,  50. ,  33.3,  30.3,\n",
        "        34.6,  34.9,  32.9,  24.1,  42.3,  48.5,  50. ,  22.6,  24.4,\n",
        "        22.5,  24.4,  20. ,  21.7,  19.3,  22.4,  28.1,  23.7,  25. ,\n",
        "        23.3,  28.7,  21.5,  23. ,  26.7,  21.7,  27.5,  30.1,  44.8,\n",
        "        50. ,  37.6,  31.6,  46.7,  31.5,  24.3,  31.7,  41.7,  48.3,\n",
        "        29. ,  24. ,  25.1,  31.5,  23.7,  23.3,  22. ,  20.1,  22.2,\n",
        "        23.7,  17.6,  18.5,  24.3,  20.5,  24.5,  26.2,  24.4,  24.8,\n",
        "        29.6,  42.8,  21.9,  20.9,  44. ,  50. ,  36. ,  30.1,  33.8,\n",
        "        43.1,  48.8,  31. ,  36.5,  22.8,  30.7,  50. ,  43.5,  20.7,\n",
        "        21.1,  25.2,  24.4,  35.2,  32.4,  32. ,  33.2,  33.1,  29.1,\n",
        "        35.1,  45.4,  35.4,  46. ,  50. ,  32.2,  22. ,  20.1,  23.2,\n",
        "        22.3,  24.8,  28.5,  37.3,  27.9,  23.9,  21.7,  28.6,  27.1,\n",
        "        20.3,  22.5,  29. ,  24.8,  22. ,  26.4,  33.1,  36.1,  28.4,\n",
        "        33.4,  28.2,  22.8,  20.3,  16.1,  22.1,  19.4,  21.6,  23.8,\n",
        "        16.2,  17.8,  19.8,  23.1,  21. ,  23.8,  23.1,  20.4,  18.5,\n",
        "        25. ,  24.6,  23. ,  22.2,  19.3,  22.6,  19.8,  17.1,  19.4,\n",
        "        22.2,  20.7,  21.1,  19.5,  18.5,  20.6,  19. ,  18.7,  32.7,\n",
        "        16.5,  23.9,  31.2,  17.5,  17.2,  23.1,  24.5,  26.6,  22.9,\n",
        "        24.1,  18.6,  30.1,  18.2,  20.6,  17.8,  21.7,  22.7,  22.6,\n",
        "        25. ,  19.9,  20.8,  16.8,  21.9,  27.5,  21.9,  23.1,  50. ,\n",
        "        50. ,  50. ,  50. ,  50. ,  13.8,  13.8,  15. ,  13.9,  13.3,\n",
        "        13.1,  10.2,  10.4,  10.9,  11.3,  12.3,   8.8,   7.2,  10.5,\n",
        "         7.4,  10.2,  11.5,  15.1,  23.2,   9.7,  13.8,  12.7,  13.1,\n",
        "        12.5,   8.5,   5. ,   6.3,   5.6,   7.2,  12.1,   8.3,   8.5,\n",
        "         5. ,  11.9,  27.9,  17.2,  27.5,  15. ,  17.2,  17.9,  16.3,\n",
        "         7. ,   7.2,   7.5,  10.4,   8.8,   8.4,  16.7,  14.2,  20.8,\n",
        "        13.4,  11.7,   8.3,  10.2,  10.9,  11. ,   9.5,  14.5,  14.1,\n",
        "        16.1,  14.3,  11.7,  13.4,   9.6,   8.7,   8.4,  12.8,  10.5,\n",
        "        17.1,  18.4,  15.4,  10.8,  11.8,  14.9,  12.6,  14.1,  13. ,\n",
        "        13.4,  15.2,  16.1,  17.8,  14.9,  14.1,  12.7,  13.5,  14.9,\n",
        "        20. ,  16.4,  17.7,  19.5,  20.2,  21.4,  19.9,  19. ,  19.1,\n",
        "        19.1,  20.1,  19.9,  19.6,  23.2,  29.8,  13.8,  13.3,  16.7,\n",
        "        12. ,  14.6,  21.4,  23. ,  23.7,  25. ,  21.8,  20.6,  21.2,\n",
        "        19.1,  20.6,  15.2,   7. ,   8.1,  13.6,  20.1,  21.8,  24.5,\n",
        "        23.1,  19.7,  18.3,  21.2,  17.5,  16.8,  22.4,  20.6,  23.9,\n",
        "        22. ,  11.9])}\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = load_boston()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "(379L, 13L)"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "(127L, 13L)"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Fitting a Linear Regression\n",
      "\n",
      "It's as easy as instantiating a new regression object (line 1) and giving your regression object your training data\n",
      "(line 2) by calling .fit(independent variables, dependent variable)\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = LinearRegression()\n",
      "clf.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "LinearRegression(copy_X=True, fit_intercept=True, normalize=False)"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Making a Prediction\n",
      "X_test is our holdout set of data.  We know the answer (y_test) but the computer does not.   \n",
      "\n",
      "Using the command below, I create a tuple for each observation, where I'm combining the real value (y_test) with\n",
      "the value our regressor predicts (clf.predict(X_test))\n",
      "\n",
      "Use a similiar format to get your r2 and mse metrics working.  Using the [scikit learn api](http://scikit-learn.org/stable/modules/model_evaluation.html) if you need help!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip (y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "[(23.100000000000001, 16.801482980348425),\n",
        " (37.0, 30.358835772059159),\n",
        " (19.399999999999999, 23.074597416504638),\n",
        " (27.5, 20.24805629573552),\n",
        " (14.4, 9.6398683398527112),\n",
        " (7.2000000000000002, 8.1423779632017883),\n",
        " (50.0, 40.176284607147629),\n",
        " (31.699999999999999, 33.28696705566577),\n",
        " (25.0, 24.857948216979839),\n",
        " (22.899999999999999, 29.198397396369852),\n",
        " (21.600000000000001, 25.322299351395223),\n",
        " (24.399999999999999, 28.595424507097388),\n",
        " (19.300000000000001, 20.360926535025683),\n",
        " (23.199999999999999, 22.572596200281339),\n",
        " (13.4, 13.377294580361072),\n",
        " (19.100000000000001, 23.779229076502347),\n",
        " (20.399999999999999, 22.802678203764888),\n",
        " (24.5, 20.424371387008208),\n",
        " (19.600000000000001, 17.783791453199868),\n",
        " (14.1, 19.102883508365196),\n",
        " (23.100000000000001, 24.259810432125569),\n",
        " (13.800000000000001, 20.031695007904041),\n",
        " (11.9, 22.322921426149179),\n",
        " (14.9, 17.084559836868138),\n",
        " (25.0, 27.590563786936677),\n",
        " (20.399999999999999, 20.004473535033629),\n",
        " (50.0, 44.37324170042249),\n",
        " (26.600000000000001, 27.794426910946086),\n",
        " (33.399999999999999, 35.686685745708978),\n",
        " (13.4, 13.806772167231479),\n",
        " (29.600000000000001, 25.200392810289841),\n",
        " (25.100000000000001, 29.743783618737268),\n",
        " (16.100000000000001, 18.495698385691622),\n",
        " (10.199999999999999, 16.975733905002354),\n",
        " (24.300000000000001, 24.181301552985783),\n",
        " (13.5, 14.101600856746003),\n",
        " (12.699999999999999, 17.689996394165739),\n",
        " (25.199999999999999, 27.224225481051963),\n",
        " (23.899999999999999, 27.39454343653864),\n",
        " (21.600000000000001, 25.022578548163985),\n",
        " (11.9, 7.4370885688196076),\n",
        " (24.100000000000001, 20.367901503940672),\n",
        " (19.699999999999999, 13.870686699694224),\n",
        " (17.100000000000001, 17.299902235063364),\n",
        " (12.6, 17.946672940140378),\n",
        " (5.5999999999999996, 12.132932882896306),\n",
        " (33.0, 23.764406794117061),\n",
        " (24.399999999999999, 23.88949130515547),\n",
        " (21.699999999999999, 20.634098584778428),\n",
        " (22.899999999999999, 20.401564978018577),\n",
        " (15.6, 11.60446706186803),\n",
        " (21.199999999999999, 21.073685619776441),\n",
        " (20.5, 21.333996415704199),\n",
        " (21.899999999999999, 14.728998628607979),\n",
        " (21.699999999999999, 22.383806429911886),\n",
        " (14.5, 18.165947880317752),\n",
        " (36.399999999999999, 32.509091031013234),\n",
        " (20.800000000000001, 17.345876076342087),\n",
        " (22.699999999999999, 21.515928602676471),\n",
        " (21.0, 22.904995674079071),\n",
        " (18.199999999999999, 19.324360017807461),\n",
        " (50.0, 43.008491562755594),\n",
        " (50.0, 36.125403089604021),\n",
        " (23.100000000000001, 24.889241374227932),\n",
        " (43.100000000000001, 36.481939082993243),\n",
        " (41.299999999999997, 32.854532940081057),\n",
        " (36.200000000000003, 27.483723357442042),\n",
        " (43.5, 38.663283437314853),\n",
        " (23.899999999999999, 27.86796689637417),\n",
        " (7.0, 8.3690026777123236),\n",
        " (19.899999999999999, 19.218291197793597),\n",
        " (29.899999999999999, 31.088209181675865),\n",
        " (23.199999999999999, 17.207066915008625),\n",
        " (24.0, 24.982001740048215),\n",
        " (18.5, 13.581536643314166),\n",
        " (23.699999999999999, 27.201537880374968),\n",
        " (21.399999999999999, 24.097549309932564),\n",
        " (15.0, 19.041180333409216),\n",
        " (23.0, 20.361172717347557),\n",
        " (16.600000000000001, 18.342616688783153),\n",
        " (31.5, 30.923875211485374),\n",
        " (9.5999999999999996, 14.460189310802928),\n",
        " (20.600000000000001, 16.651198341754547),\n",
        " (16.699999999999999, 19.438194038144534),\n",
        " (48.799999999999997, 40.60941096548656),\n",
        " (22.600000000000001, 22.762986918235569),\n",
        " (23.100000000000001, 22.384498484332411),\n",
        " (22.0, 27.438289475431294),\n",
        " (19.300000000000001, 17.103718279283292),\n",
        " (35.399999999999999, 31.379510019430967),\n",
        " (22.600000000000001, 26.847378547149546),\n",
        " (27.5, 12.6182913373151),\n",
        " (21.100000000000001, 20.671590161291171),\n",
        " (35.100000000000001, 34.993848905121077),\n",
        " (36.5, 35.043837028683583),\n",
        " (19.899999999999999, 17.644008322944231),\n",
        " (24.5, 27.352664601400704),\n",
        " (16.800000000000001, 20.279299731691999),\n",
        " (22.300000000000001, 27.050626595535014),\n",
        " (23.300000000000001, 28.306787615725099),\n",
        " (14.199999999999999, 17.818884262992093),\n",
        " (28.100000000000001, 25.406194977498775),\n",
        " (19.0, 21.289499314073176),\n",
        " (19.399999999999999, 25.046062277876509),\n",
        " (23.100000000000001, 9.6681441586141439),\n",
        " (17.5, 17.092461635711803),\n",
        " (17.600000000000001, 16.242969896798115),\n",
        " (19.800000000000001, 21.108334253189696),\n",
        " (33.299999999999997, 35.593341227242206),\n",
        " (12.1, 18.352117643881638),\n",
        " (42.299999999999997, 36.81110506823822),\n",
        " (19.300000000000001, 21.990349450031818),\n",
        " (8.0999999999999996, 3.9143653613352924),\n",
        " (31.600000000000001, 32.724816202058349),\n",
        " (11.0, 14.342466270385017),\n",
        " (24.399999999999999, 24.328899594387689),\n",
        " (10.199999999999999, 6.3518387064336821),\n",
        " (20.5, 19.93649008757961),\n",
        " (16.199999999999999, 15.436691052650527),\n",
        " (10.5, 5.8768205100287254),\n",
        " (21.199999999999999, 21.511884185501138),\n",
        " (16.100000000000001, 21.481191034814312),\n",
        " (27.899999999999999, 19.453730239613861),\n",
        " (21.399999999999999, 24.527334851339496),\n",
        " (20.199999999999999, 22.164526404193285),\n",
        " (18.300000000000001, 18.846932057476224),\n",
        " (22.399999999999999, 23.840224822548748)]"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implement scikit learn's r2 and mse method to measure the performance of my linear regressor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r2_score(y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "0.75197721423058905"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_squared_error(y_test, clf.predict(X_test))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "21.120227547293286"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Implement sklearn.linear_model.Ridge or sklearn.linear_model.Lasso"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import Ridge\n",
      "import numpy as np\n",
      "#n_samples, n_features = 10, 5\n",
      "#np.random.seed(0)\n",
      "#y = np.random.randn(n_samples)\n",
      "#X = np.random.randn(n_samples, n_features)\n",
      "clf = Ridge(alpha = 1.0)\n",
      "clf.fit(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "0.77806458186120109"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Optimize the regression model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_opt = Ridge(alpha = 0.000000001)\n",
      "clf_opt.fit(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "Ridge(alpha=1e-09, copy_X=True, fit_intercept=True, max_iter=None,\n",
        "   normalize=False, solver='auto', tol=0.001)"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf_opt.score(X_test, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 74,
       "text": [
        "0.77818079505452264"
       ]
      }
     ],
     "prompt_number": 74
    }
   ],
   "metadata": {}
  }
 ]
}